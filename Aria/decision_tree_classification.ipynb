{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Office'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\petru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\petru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\petru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Office'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m payroll[numeric_cols] \u001b[39m=\u001b[39m payroll[numeric_cols]\u001b[39m.\u001b[39mclip(lower\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     11\u001b[0m payroll\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m payroll[\u001b[39m'\u001b[39m\u001b[39mOffice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payroll[\u001b[39m'\u001b[39;49m\u001b[39mOffice\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[39m# define column for 1/4 year discretization\u001b[39;00m\n\u001b[0;32m     15\u001b[0m payroll[\u001b[39m'\u001b[39m\u001b[39mFiscal Quarter\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payroll[\u001b[39m'\u001b[39m\u001b[39mFiscal Quarter\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m0.25\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.25\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\petru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\petru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Office'"
     ]
    }
   ],
   "source": [
    "# read table\n",
    "\n",
    "dataPayment = '../Datasets/Employee_Payroll.csv'\n",
    "payroll = pd.read_csv(dataPayment)\n",
    "\n",
    "# set default value to 0 for NaN numerical data\n",
    "numeric_cols = payroll.select_dtypes(include=[np.number]).columns\n",
    "payroll[numeric_cols] = payroll[numeric_cols].clip(lower=0)\n",
    "\n",
    "\n",
    "payroll.fillna(0, inplace=True)\n",
    "payroll['Office'] = payroll['Office'].astype(int)\n",
    "\n",
    "# define column for 1/4 year discretization\n",
    "payroll['Fiscal Quarter'] = payroll['Fiscal Quarter']*0.25 - 0.25\n",
    "payroll['Fiscal Period'] = payroll['Fiscal Year'] + payroll['Fiscal Quarter']\n",
    "\n",
    "pd.to_datetime(payroll['Original Hire Date'])\n",
    "\n",
    "# parse hire date to get hire year\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].str.split('/').str[2]\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].astype(int)\n",
    "\n",
    "_work_year = payroll[\"Fiscal Period\"] - payroll['Original Hire Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeconverter(col):\n",
    "    if col == \"Iris-setosa\":\n",
    "        return 0\n",
    "    if col == \"Iris-versicolor\":\n",
    "        return 1\n",
    "    if col == \"Iris-virginica\":\n",
    "        return 2\n",
    "\n",
    "col_names = ['sepal length', 'sepal width', 'petal_length', 'petal_width', 'type']\n",
    "data = pd.read_csv('../Datasets/iris.data', skiprows=1, header=None, names=col_names, converters={\n",
    "    'type': typeconverter\n",
    "})\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fiscal Year</th>\n",
       "      <th>Fiscal Period</th>\n",
       "      <th>Job Code</th>\n",
       "      <th>Position ID</th>\n",
       "      <th>Base Pay</th>\n",
       "      <th>Working Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>1172</td>\n",
       "      <td>9510200</td>\n",
       "      <td>20088.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016.25</td>\n",
       "      <td>1172</td>\n",
       "      <td>9510200</td>\n",
       "      <td>23436.00</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016.50</td>\n",
       "      <td>1172</td>\n",
       "      <td>9510200</td>\n",
       "      <td>20422.82</td>\n",
       "      <td>11.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>1172</td>\n",
       "      <td>9510200</td>\n",
       "      <td>23904.80</td>\n",
       "      <td>11.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fiscal Year  Fiscal Period  Job Code  Position ID  Base Pay  Working Year\n",
       "0         2016        2016.00      1172      9510200  20088.00         11.00\n",
       "1         2016        2016.25      1172      9510200  23436.00         11.25\n",
       "2         2016        2016.50      1172      9510200  20422.82         11.50\n",
       "3         2016        2016.75      1172      9510200  23904.80         11.75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify table column included\n",
    "\n",
    "data = payroll[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Position ID', 'Base Pay']]\n",
    "\n",
    "# add Working Year Column\n",
    "payroll[\"Working Year\"] = _work_year\n",
    "data = payroll[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Position ID', 'Base Pay', 'Working Year']]\n",
    "data.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        self.value = value # leaf node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        ''' constructor '''\n",
    "        \n",
    "        # initialize the root of the tree \n",
    "        self.root = None\n",
    "        \n",
    "        # stopping conditions\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        ''' recursive function to build the tree ''' \n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        \n",
    "        # split until stopping conditions are met\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # find the best split\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "        # compute leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split '''\n",
    "        \n",
    "        # dictionary to store the best split\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        # loop over all the features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # loop over all the feature values present in the data\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # compute information gain\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # update the best split if needed\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "                        \n",
    "        # return best split\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        ''' function to split the data '''\n",
    "        \n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        ''' function to compute information gain '''\n",
    "        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        ''' function to compute entropy '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        ''' function to compute gini index '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ''' function to train the tree '''\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' function to predict new dataset '''\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' function to predict a single data point '''\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.016000e+03, 2.016000e+03, 1.172000e+03, 9.510200e+06,\n",
       "        2.008800e+04, 1.100000e+01],\n",
       "       [2.016000e+03, 2.016250e+03, 1.172000e+03, 9.510200e+06,\n",
       "        2.343600e+04, 1.125000e+01],\n",
       "       [2.016000e+03, 2.016500e+03, 1.172000e+03, 9.510200e+06,\n",
       "        2.042282e+04, 1.150000e+01],\n",
       "       ...,\n",
       "       [2.018000e+03, 2.018000e+03, 1.567000e+03, 9.512421e+06,\n",
       "        1.921740e+04, 3.300000e+01],\n",
       "       [2.018000e+03, 2.018000e+03, 5.296000e+03, 9.519643e+06,\n",
       "        9.698800e+03, 2.000000e+00],\n",
       "       [2.018000e+03, 2.018250e+03, 4.800000e+01, 1.400088e+06,\n",
       "        1.287244e+04, 7.250000e+00]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,3:-1].values\n",
    "Y = data.iloc[:,-2].values.reshape(-1, 1)\n",
    "\n",
    "# X = data[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Position ID', 'Working Year']]\n",
    "# Y = data[['Base Pay']]\n",
    "\n",
    "X = data.iloc[:].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)\n",
    "\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m DecisionTreeClassifier(min_samples_split\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39mprint_tree()\n",
      "Cell \u001b[1;32mIn[4], line 133\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39m\u001b[39m\u001b[39m''' function to train the tree '''\u001b[39;00m\n\u001b[0;32m    132\u001b[0m dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((X, Y), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_tree(dataset)\n",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.build_tree\u001b[1;34m(self, dataset, curr_depth)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# split until stopping conditions are met\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mif\u001b[39;00m num_samples\u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split \u001b[39mand\u001b[39;00m curr_depth\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth:\n\u001b[0;32m     20\u001b[0m     \u001b[39m# find the best split\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     best_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_best_split(dataset, num_samples, num_features)\n\u001b[0;32m     22\u001b[0m     \u001b[39m# check if information gain is positive\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m best_split[\u001b[39m\"\u001b[39m\u001b[39minfo_gain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m     24\u001b[0m         \u001b[39m# recur left\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.get_best_split\u001b[1;34m(self, dataset, num_samples, num_features)\u001b[0m\n\u001b[0;32m     54\u001b[0m y, left_y, right_y \u001b[39m=\u001b[39m dataset[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], dataset_left[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], dataset_right[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     55\u001b[0m \u001b[39m# compute information gain\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m curr_info_gain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minformation_gain(y, left_y, right_y, \u001b[39m\"\u001b[39;49m\u001b[39mgini\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     57\u001b[0m \u001b[39m# update the best split if needed\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m curr_info_gain\u001b[39m>\u001b[39mmax_info_gain:\n",
      "Cell \u001b[1;32mIn[4], line 82\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.information_gain\u001b[1;34m(self, parent, l_child, r_child, mode)\u001b[0m\n\u001b[0;32m     80\u001b[0m weight_r \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(r_child) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(parent)\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m mode\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgini\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 82\u001b[0m     gain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgini_index(parent) \u001b[39m-\u001b[39m (weight_l\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgini_index(l_child) \u001b[39m+\u001b[39m weight_r\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgini_index(r_child))\n\u001b[0;32m     83\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     gain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentropy(parent) \u001b[39m-\u001b[39m (weight_l\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentropy(l_child) \u001b[39m+\u001b[39m weight_r\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentropy(r_child))\n",
      "Cell \u001b[1;32mIn[4], line 103\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.gini_index\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    101\u001b[0m gini \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m class_labels:\n\u001b[1;32m--> 103\u001b[0m     p_cls \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(y[y \u001b[39m==\u001b[39;49m \u001b[39mcls\u001b[39;49m]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y)\n\u001b[0;32m    104\u001b[0m     gini \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m p_cls\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m    105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m gini\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "model.fit(X_train, Y_train)\n",
    "model.print_tree()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
