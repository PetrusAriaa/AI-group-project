{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table\n",
    "\n",
    "dataPayment = '../Datasets/Employee_Payroll.csv'\n",
    "payroll = pd.read_csv(dataPayment)\n",
    "\n",
    "# set default value to 0 for NaN numerical data\n",
    "numeric_cols = payroll.select_dtypes(include=[np.number]).columns\n",
    "payroll[numeric_cols] = payroll[numeric_cols].clip(lower=0)\n",
    "\n",
    "\n",
    "payroll.fillna(0, inplace=True)\n",
    "payroll['Office'] = payroll['Office'].astype(int)\n",
    "\n",
    "# define column for 1/4 year discretization\n",
    "payroll['Fiscal Quarter'] = payroll['Fiscal Quarter']*0.25 - 0.25\n",
    "payroll['Fiscal Period'] = payroll['Fiscal Year'] + payroll['Fiscal Quarter']\n",
    "\n",
    "pd.to_datetime(payroll['Original Hire Date'])\n",
    "\n",
    "# parse hire date to get hire year\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].str.split('/').str[2]\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].astype(int)\n",
    "\n",
    "_work_year = payroll[\"Fiscal Period\"] - payroll['Original Hire Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify table column included\n",
    "\n",
    "payroll = payroll[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Job Title', 'Base Pay', 'Position ID', 'Employee Identifier']]\n",
    "\n",
    "# add Working Year Column\n",
    "payroll[\"Working Year\"] = _work_year\n",
    "\n",
    "payroll.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aku gatau kenapa tapi ini error di tempatku pas buat cache jadi run yang bawahnya ini aja\n",
    "\n",
    "arr = []\n",
    "\n",
    "try:\n",
    "    with open('../cache/ids.txt', \"r\") as f:\n",
    "        for _id in f:\n",
    "            arr.append(int(_id))\n",
    "except:\n",
    "    if not os.path.exists('../cache'):\n",
    "        os.mkdir('../cache')\n",
    "        \n",
    "    _index = payroll['Job Code'].unique()\n",
    "    for _id in _index:\n",
    "        counts = len(payroll.groupby(['Job Code']).get_group(_id))\n",
    "        if counts > 1000:\n",
    "            arr.append(str(_id))\n",
    "    with open('cache/ids.txt', 'w') as f:\n",
    "        for _id in arr:\n",
    "            f.write('%s\\n' % _id)\n",
    "    with open('cache/ids.txt', 'r') as f:\n",
    "        arr = []\n",
    "        for _id in f:\n",
    "            arr.append(int(_id)) \n",
    "finally:\n",
    "   f.close()\n",
    "\n",
    "# :return : <List> arr : list of unique job id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jadi pake ini buat ngisi arr nya, tp ga ngebuat cache\n",
    "\n",
    "arr = []\n",
    "\n",
    "_index = payroll['Job Code'].unique()\n",
    "for _id in _index:\n",
    "    counts = len(payroll.groupby(['Job Code']).get_group(_id))\n",
    "    if counts > 1000:\n",
    "        arr.append(_id)\n",
    "\n",
    "\n",
    "\n",
    "# :return : <List> arr : list of unique job id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emps = []\n",
    "max = 0\n",
    "for _id in arr:\n",
    "    df = payroll[payroll['Job Code'] == _id]\n",
    "    emp_id = df['Employee Identifier'].unique()\n",
    "    if len(emp_id) > 50:\n",
    "        l = 75\n",
    "    else:\n",
    "        l = len(emp_id)\n",
    "\n",
    "    for i in range(l):\n",
    "        for i in range(100):\n",
    "            _index = np.random.randint(0, l-1)\n",
    "            if emp_id[_index] not in emps:\n",
    "                emps.append(emp_id[_index])\n",
    "                break\n",
    "\n",
    "\n",
    "len(emps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = payroll[payroll['Employee Identifier'].isin(emps)]\n",
    "df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = df_id.drop(['Job Title', 'Employee Identifier'], axis=1)\n",
    "X = up[['Job Code', 'Working Year', 'Position ID', 'Fiscal Period', 'Fiscal Year']]\n",
    "y = up['Base Pay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix  = up.corr()\n",
    "correlation_matrix['Base Pay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = up.drop(\"Base Pay\", axis=1).values\n",
    "y = up[\"Base Pay\"].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 15 menit\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from collections import Counter\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        final_output = []\n",
    "        for i in range(len(X_test)):\n",
    "            d = []\n",
    "            votes = []\n",
    "            for j in range(len(X_train)):\n",
    "                dist = distance.euclidean(X_train[j] , X_test[i])\n",
    "                d.append([dist, j])\n",
    "            d.sort()\n",
    "            d = d[0:self.k]\n",
    "            for d, j in d:\n",
    "                votes.append(y_train[j])\n",
    "            ans = Counter(votes).most_common(1)[0][0]\n",
    "            final_output.append(ans)\n",
    "            \n",
    "        return final_output\n",
    "    \n",
    "clf = KNN(3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COBA PAKE LIBRARY\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors = 3)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "knn.score(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dari sini kebawah yg errornya 6000an :)\n",
    "\n",
    "dist = []\n",
    "for row in X_test:\n",
    "    d = np.linalg.norm(X_train - row, axis = 1)\n",
    "    dist.append(d)\n",
    "dist = np.array(dist)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "nearest = np.argsort(dist, axis=1)\n",
    "nearest = nearest[:, :k]\n",
    "nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nearest = y[nearest]\n",
    "y_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.mean(y_nearest, axis=1)\n",
    "y_pred\n",
    "# import scipy\n",
    "# y_pred = scipy.stats.mode(y_nearest, axis=1)[0].flatten()\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "x = df_id['Job Code']\n",
    "y = df_id['Working Year']\n",
    "z = df_id['Base Pay']\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z,\n",
    "           linewidths=1, alpha=.7,\n",
    "           edgecolor='k',\n",
    "           s = 200,\n",
    "           c=z)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ccb58c476f33ba3e3aee7ac07234ef6b8217ef24ad64d2a7d4fed1a57c1cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
