{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table\n",
    "\n",
    "dataPayment = '../Datasets/Employee_Payroll.csv'\n",
    "payroll = pd.read_csv(dataPayment)\n",
    "\n",
    "# set default value to 0 for NaN numerical data\n",
    "numeric_cols = payroll.select_dtypes(include=[np.number]).columns\n",
    "payroll[numeric_cols] = payroll[numeric_cols].clip(lower=0)\n",
    "\n",
    "\n",
    "payroll.fillna(0, inplace=True)\n",
    "payroll['Office'] = payroll['Office'].astype(int)\n",
    "\n",
    "# define column for 1/4 year discretization\n",
    "payroll['Fiscal Quarter'] = payroll['Fiscal Quarter']*0.25 - 0.25\n",
    "payroll['Fiscal Period'] = payroll['Fiscal Year'] + payroll['Fiscal Quarter']\n",
    "\n",
    "pd.to_datetime(payroll['Original Hire Date'])\n",
    "\n",
    "# parse hire date to get hire year\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].str.split('/').str[2]\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].astype(int)\n",
    "\n",
    "_work_year = payroll[\"Fiscal Period\"] - payroll['Original Hire Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify table column included\n",
    "\n",
    "payroll = payroll[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Job Title', 'Base Pay', 'Position ID', 'Employee Identifier']]\n",
    "\n",
    "# add Working Year Column\n",
    "payroll[\"Working Year\"] = _work_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payroll.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payroll.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melihat heatmap korelasi antarkolom di dataframe Covid\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "sns.heatmap(payroll.corr(), annot=True, fmt='.1g', cmap=\"Blues\", cbar=True, linewidths=0.5, linecolor='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pengecekan korelasi dengan death event\n",
    "corr = payroll.corr()\n",
    "corr['Base Pay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot korelasi dengan base pay\n",
    "sns.heatmap(corr[-1:], annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YANG INI JANGAN DIJALANKAN DULU YA GESSS :'\n",
    "\n",
    "arr = []\n",
    "\n",
    "try:\n",
    "    with open('./cache/ids.txt', \"r\") as f:\n",
    "        for _id in f:\n",
    "            arr.append(int(_id))\n",
    "except:\n",
    "    if not os.path.exists('./cache'):\n",
    "        os.mkdir('./cache')\n",
    "        \n",
    "    _index = payroll['Job Code'].unique()\n",
    "    for _id in _index:\n",
    "        counts = len(payroll.groupby(['Job Code']).get_group(_id))\n",
    "        if counts > 1000:\n",
    "            arr.append(str(_id))\n",
    "    with open('cache/ids.txt', 'w') as f:\n",
    "        for _id in arr:\n",
    "            f.write('%s\\n' % _id)\n",
    "    with open('cache/ids.txt', 'r') as f:\n",
    "        arr = []\n",
    "        for _id in f:\n",
    "            arr.append(int(_id)) \n",
    "finally:\n",
    "   f.close()\n",
    "\n",
    "# :return : <List> arr : list of unique job id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emps = []\n",
    "max = 0;\n",
    "for _id in arr:\n",
    "    df = payroll[payroll['Job Code'] == _id]\n",
    "    emp_id = df['Employee Identifier'].unique()\n",
    "    if len(emp_id) > 50:\n",
    "        l = 75\n",
    "    else:\n",
    "        l = len(emp_id)\n",
    "\n",
    "    for i in range(l):\n",
    "        for i in range(100):\n",
    "            _index = np.random.randint(0, l-1)\n",
    "            if emp_id[_index] not in emps:\n",
    "                emps.append(emp_id[_index])\n",
    "                break\n",
    "\n",
    "\n",
    "len(emps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = payroll[payroll['Employee Identifier'].isin(emps)]\n",
    "df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeTree():\n",
    "    def __init__(cons, attributes=None, threshold=None, left=None, right=None, infoGain=None, value=None):\n",
    "        \n",
    "        ''' constructor ''' \n",
    "        # Untuk decision node\n",
    "        cons.attributes = attributes\n",
    "        cons.threshold = threshold\n",
    "        cons.left = left\n",
    "        cons.right = right\n",
    "        cons.infoGain = infoGain\n",
    "        \n",
    "        # Untuk leaf node\n",
    "        cons.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(cons, minSplit=2, maxDepth=3):\n",
    "        ''' constructor '''\n",
    "        \n",
    "        # Inisialisasi root tree\n",
    "        cons.root = None\n",
    "        \n",
    "        # Kondisi untuk menghentikan percabangan\n",
    "        cons.minSplit = minSplit\n",
    "        cons.maxDepth = maxDepth\n",
    "        \n",
    "    def build_tree(cons, dataset, currentDepth=0):\n",
    "        ''' fungsi rekursif untuk membangun tree ''' \n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        sizeSamples, sizeAttributes = np.shape(X)\n",
    "        \n",
    "        # Melakukan percabangan sampai kondisi tidak memenuhi\n",
    "        if sizeSamples >= cons.minSplit and currentDepth <= cons.maxDepth:\n",
    "            # Cari attribute untuk percabangan terbaik\n",
    "            bestAttribute = cons.find_best_attribute(dataset, sizeSamples, sizeAttributes)\n",
    "            \n",
    "            # Cek apakah information gain lebih dari 0, jika iya maka bisa dilanjutkan\n",
    "            if bestAttribute[\"infoGain\"] > 0:\n",
    "                # rekursif untuk membentuk left subtree sampai pada leaf\n",
    "                leftSubtree = cons.build_tree(bestAttribute[\"datasetLeft\"], currentDepth+1)\n",
    "                \n",
    "                # rekursif untuk membentuk right subtree sampai pada leaf\n",
    "                rightSubtree = cons.build_tree(bestAttribute[\"datasetRight\"], currentDepth+1)\n",
    "                \n",
    "                # return node decision\n",
    "                return NodeTree(bestAttribute[\"attributes\"], bestAttribute[\"threshold\"], \n",
    "                                leftSubtree, rightSubtree, bestAttribute[\"infoGain\"])\n",
    "        \n",
    "        # hitung leaf node\n",
    "        leafValue = cons.calculate_leaf(Y)\n",
    "        # return leaf node\n",
    "        return NodeTree(value=leafValue)\n",
    "    \n",
    "    def find_best_attribute(cons, dataset, sizeSamples, sizeAttributes):\n",
    "        ''' fungsi untuk mencari attribute terbaik '''\n",
    "        \n",
    "        # dictionary yang digunakan untuk menyimpan attribute terbaik\n",
    "        bestAttribute = {}\n",
    "        maxInfoGain = -float(\"inf\")\n",
    "        \n",
    "        # loop untuk melihat keseluruhan attributes\n",
    "        for attributes in range(sizeAttributes):\n",
    "            attributeValues = dataset[:, attributes]\n",
    "            posTreshold = np.unique(attributeValues)\n",
    "            \n",
    "            # loop untuk keseluruhan nilai dari attributes di dataset\n",
    "            for threshold in posTreshold:\n",
    "                # mengambil percabangan yang terbaru\n",
    "                datasetLeft, datasetRight = cons.split(dataset, attributes, threshold)\n",
    "                \n",
    "                # cek apakah child tree tidak kosong\n",
    "                if len(datasetLeft)>0 and len(datasetRight)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], datasetLeft[:, -1], datasetRight[:, -1]\n",
    "                    \n",
    "                    # hitung information gain\n",
    "                    currentInfoGain = cons.calculate_information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # update percabangan terbaik apabila ada\n",
    "                    if currentInfoGain>maxInfoGain:\n",
    "                        bestAttribute[\"attributes\"] = attributes\n",
    "                        bestAttribute[\"threshold\"] = threshold\n",
    "                        bestAttribute[\"datasetLeft\"] = datasetLeft\n",
    "                        bestAttribute[\"datasetRight\"] = datasetRight\n",
    "                        bestAttribute[\"infoGain\"] = currentInfoGain\n",
    "                        maxInfoGain = currentInfoGain\n",
    "                        \n",
    "        # return attribute terbaik\n",
    "        return bestAttribute\n",
    "    \n",
    "    def split(cons, dataset, attributes, threshold):\n",
    "        ''' fungsi untuk membuat cabang '''\n",
    "        \n",
    "        datasetLeft = np.array([row for row in dataset if row[attributes] <= threshold])\n",
    "        datasetRight = np.array([row for row in dataset if row[attributes] > threshold])\n",
    "        return datasetLeft, datasetRight\n",
    "    \n",
    "    def calculate_information_gain(cons, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        ''' fungsi untuk menghitung information gain '''\n",
    "        \n",
    "        lengthLeft = len(l_child) / len(parent)\n",
    "        lengthRight = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = cons.giniValue(parent) - (lengthLeft*cons.giniValue(l_child) + lengthRight*cons.giniValue(r_child))\n",
    "        else:\n",
    "            gain = cons.entropy(parent) - (lengthLeft*cons.entropy(l_child) + lengthRight*cons.entropy(r_child))\n",
    "        return gain\n",
    "    \n",
    "    def entropy(cons, y):\n",
    "        ''' fungsi untuk menghitung entropy '''\n",
    "        \n",
    "        labelClass = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in labelClass:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "    \n",
    "    def giniValue(cons, y):\n",
    "        ''' fungsi untuk menghitung nilai gini '''\n",
    "        \n",
    "        labelClass = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in labelClass:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf(cons, Y):\n",
    "        ''' fungsi untuk menghitung node leaf '''\n",
    "        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def print_tree(cons, tree=None, indent=\" \"):\n",
    "        ''' fungsi untuk menampilkan tree yang sudah jadi '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = cons.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(covid.columns[tree.attributes], \"=\", tree.threshold, \"?\", tree.infoGain)\n",
    "            print(\"%sbenar: \" % (indent), end=\" \")\n",
    "            cons.print_tree(tree.left, indent + indent)\n",
    "            print(\"%ssalah: \" % (indent), end=\" \")\n",
    "            cons.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def fit(cons, X, Y):\n",
    "        ''' fungsi untuk melatih tree '''\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        cons.root = cons.build_tree(dataset)\n",
    "    \n",
    "    def predict(cons, X):\n",
    "        ''' fungsi untuk memprediksi dataset '''\n",
    "        \n",
    "        predictions = [cons.make_prediction(x, cons.root) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    def make_prediction(cons, x, tree):\n",
    "        ''' fungsi untuk memprediksi single data point '''\n",
    "        \n",
    "        if tree.value!=None: \n",
    "          return tree.value\n",
    "        feature_val = x[tree.attributes]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return cons.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return cons.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrixs(pred, original): #pass predicted and original labels to this function\n",
    "    matrix=np.zeros((2,2)) # form an empty matric of 2x2\n",
    "    for i in range(len(pred)): #the confusion matrix is for 2 classes: 1,0\n",
    "        #1=positive, 0=negative\n",
    "        if int(pred[i])==1 and int(original[i])==1: \n",
    "            matrix[0,0]+=1 #True Positives\n",
    "        elif int(pred[i])==1 and int(original[i])==0:\n",
    "            matrix[0,1]+=1 #False Positives\n",
    "        elif int(pred[i])==0 and int(original[i])==1:\n",
    "            matrix[1,0]+=1 #False Negatives\n",
    "        elif int(pred[i])==0 and int(original[i])==0:\n",
    "            matrix[1,1]+=1 #True Negatives\n",
    "    precision=matrix[0,0]/(matrix[0,0]+matrix[0,1])\n",
    "    print(\"Precision:\",precision)\n",
    "    recall=matrix[0,0]/(matrix[0,0]+matrix[1,0])\n",
    "    print(\"Recall:\",recall)\n",
    "    specificity=matrix[1,1]/(matrix[0,1]+matrix[1,1])\n",
    "    print(\"Specificity:\",specificity)\n",
    "    negative_pred_value=matrix[1,1]/(matrix[1,0]+matrix[1,1])\n",
    "    print(\"Negative Predicted Value:\",negative_pred_value)\n",
    "    f2=  2*(precision*recall)/(precision+recall)\n",
    "    print(\"F1 score:\",f2)\n",
    "\n",
    "    #the above code adds up the frequencies of the tps,tns,fps,fns and a matrix is formed\n",
    "    return matrix\n",
    "\n",
    "def accuracy_metric(pred, original):\n",
    "  correct = 0\n",
    "  for i in range(len(original)):\n",
    "    if original[i] == pred[i]:\n",
    "      correct += 1\n",
    "  return correct / float(len(original)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menyiapkan dataset train dan test\n",
    "\n",
    "X = df_id.iloc[:, :-1].values\n",
    "Y = df_id.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split_data(X, Y):\n",
    "    arr_rand = np.random.rand(X.shape[0])\n",
    "    split = arr_rand < np.percentile(arr_rand, 80)\n",
    "\n",
    "    X_train = X[split]\n",
    "    Y_train = Y[split]\n",
    "    X_test =  X[~split]\n",
    "    Y_test = Y[~split]\n",
    "\n",
    "    print(len(X_train), len(Y_train), len(X_test), len(Y_test))\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "try:\n",
    "    X_train, Y_train, X_test, Y_test = shuffle_split_data(X, Y)\n",
    "    print(\"Successful\")\n",
    "except:\n",
    "    print(\"Fail\")\n",
    "\n",
    "print('------------')\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(Y_train)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(minSplit=3, maxDepth=3)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrixs(Y_pred,Y_test)\n",
    "print('-------------------------------------------------')\n",
    "print(confusion)\n",
    "accuracy = accuracy_metric(Y_pred, Y_test)\n",
    "print('-------------------------------------------------')\n",
    "print(\"Test accuracy: {} %\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
