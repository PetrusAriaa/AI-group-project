{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table\n",
    "\n",
    "dataPayment = '../Datasets/Employee_Payroll.csv'\n",
    "payroll = pd.read_csv(dataPayment)\n",
    "\n",
    "# set default value to 0 for NaN numerical data\n",
    "numeric_cols = payroll.select_dtypes(include=[np.number]).columns\n",
    "payroll[numeric_cols] = payroll[numeric_cols].clip(lower=0)\n",
    "\n",
    "\n",
    "payroll.fillna(0, inplace=True)\n",
    "payroll['Office'] = payroll['Office'].astype(int)\n",
    "\n",
    "# define column for 1/4 year discretization\n",
    "payroll['Fiscal Quarter'] = payroll['Fiscal Quarter']*0.25 - 0.25\n",
    "payroll['Fiscal Period'] = payroll['Fiscal Year'] + payroll['Fiscal Quarter']\n",
    "\n",
    "pd.to_datetime(payroll['Original Hire Date'])\n",
    "\n",
    "# parse hire date to get hire year\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].str.split('/').str[2]\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].astype(int)\n",
    "\n",
    "_work_year = payroll[\"Fiscal Period\"] - payroll['Original Hire Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify table column included\n",
    "\n",
    "payroll = payroll[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Job Title', 'Base Pay', 'Position ID', 'Employee Identifier']]\n",
    "\n",
    "# add Working Year Column\n",
    "payroll[\"Working Year\"] = _work_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YANG INI JANGAN DIJALANKAN DULU YA GESSS :'\n",
    "\n",
    "arr = []\n",
    "\n",
    "try:\n",
    "    with open('./cache/ids.txt', \"r\") as f:\n",
    "        for _id in f:\n",
    "            arr.append(int(_id))\n",
    "except:\n",
    "    if not os.path.exists('./cache'):\n",
    "        os.mkdir('./cache')\n",
    "        \n",
    "    _index = payroll['Job Code'].unique()\n",
    "    for _id in _index:\n",
    "        counts = len(payroll.groupby(['Job Code']).get_group(_id))\n",
    "        if counts > 1000:\n",
    "            arr.append(str(_id))\n",
    "    with open('cache/ids.txt', 'w') as f:\n",
    "        for _id in arr:\n",
    "            f.write('%s\\n' % _id)\n",
    "    with open('cache/ids.txt', 'r') as f:\n",
    "        arr = []\n",
    "        for _id in f:\n",
    "            arr.append(int(_id)) \n",
    "finally:\n",
    "   f.close()\n",
    "\n",
    "# :return : <List> arr : list of unique job id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emps = []\n",
    "max = 0;\n",
    "for _id in arr:\n",
    "    df = payroll[payroll['Job Code'] == _id]\n",
    "    emp_id = df['Employee Identifier'].unique()\n",
    "    if len(emp_id) > 50:\n",
    "        l = 75\n",
    "    else:\n",
    "        l = len(emp_id)\n",
    "\n",
    "    for i in range(l):\n",
    "        for i in range(100):\n",
    "            _index = np.random.randint(0, l-1)\n",
    "            if emp_id[_index] not in emps:\n",
    "                emps.append(emp_id[_index])\n",
    "                break\n",
    "\n",
    "\n",
    "len(emps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = payroll[payroll['Employee Identifier'].isin(emps)]\n",
    "df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features & manually splitting the dataset & selecting survived as our target variable\n",
    "features = ['Job Code', 'Working Year', 'Position ID', 'Fiscal Period', 'Fiscal Year']\n",
    "nb_train = int(np.floor(0.8 * len(payroll)))\n",
    "df = payroll.sample(frac=1, random_state=217)\n",
    "X_train = df[features][:nb_train]\n",
    "y_train = df['Base Pay'][:nb_train].values\n",
    "X_test = df[features][nb_train:]\n",
    "y_test = df['Base Pay'][nb_train:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define entropy\n",
    "def entropy(p):\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    elif p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return - (p * np.log2(p) + (1 - p) * np.log2(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define information gain\n",
    "def information_gain(left_child, right_child):\n",
    "    parent = left_child + right_child\n",
    "    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
    "    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
    "    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
    "    IG_p = entropy(p_parent)\n",
    "    IG_l = entropy(p_left)\n",
    "    IG_r = entropy(p_right)\n",
    "    return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bootstrap(X_train, y_train):\n",
    "    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
    "    oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
    "    X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
    "    y_bootstrap = y_train[bootstrap_indices]\n",
    "    X_oob = X_train.iloc[oob_indices].values\n",
    "    y_oob = y_train[oob_indices]\n",
    "    return X_bootstrap, y_bootstrap, X_oob, y_oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oob_score(tree, X_test, y_test):\n",
    "    mis_label = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = predict_tree(tree, X_test[i])\n",
    "        if pred != y_test[i]:\n",
    "            mis_label += 1\n",
    "    return mis_label / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding split point\n",
    "def find_split_point(X_bootstrap, y_bootstrap, max_features):\n",
    "    feature_ls = list()\n",
    "    num_features = len(X_bootstrap[0])\n",
    "\n",
    "    while len(feature_ls) <= max_features:\n",
    "        feature_idx = random.sample(range(num_features), 1)\n",
    "    if feature_idx not in feature_ls:\n",
    "        feature_ls.extend(feature_idx)\n",
    "\n",
    "    best_info_gain = -999\n",
    "    node = None\n",
    "    for feature_idx in feature_ls:\n",
    "      for split_point in X_bootstrap[:,feature_idx]:\n",
    "        left_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "        right_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "\n",
    "        # split children for continuous variables\n",
    "        if type(split_point) in [int, float]:\n",
    "            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                if value <= split_point:\n",
    "                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    left_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                else:\n",
    "                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    right_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "        # split children for categoric variables\n",
    "        else:\n",
    "            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
    "                if value == split_point:\n",
    "                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    left_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "                else:\n",
    "                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    right_child['y_bootstrap'].append(y_bootstrap[i])\n",
    "\n",
    "        split_info_gain = information_gain(left_child['y_bootstrap'], right_child['y_bootstrap'])\n",
    "        if split_info_gain > best_info_gain:\n",
    "            best_info_gain = split_info_gain\n",
    "            left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
    "            right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
    "            node = {'information_gain': split_info_gain,\n",
    "                    'left_child': left_child,\n",
    "                    'right_child': right_child,\n",
    "                    'split_point': split_point,\n",
    "                    'feature_idx': feature_idx}\n",
    "\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define terminal node\n",
    "def terminal_node(node):\n",
    "    y_bootstrap = node['y_bootstrap']\n",
    "    pred = max(y_bootstrap, key = y_bootstrap.count)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define split node\n",
    "def split_node(node, max_features, min_samples_split, max_depth, depth):\n",
    "    left_child = node['left_child']\n",
    "    right_child = node['right_child']\n",
    "\n",
    "    del(node['left_child'])\n",
    "    del(node['right_child'])\n",
    "\n",
    "    if len(left_child['y_bootstrap']) == 0 or len(right_child['y_bootstrap']) == 0:\n",
    "        empty_child = {'y_bootstrap': left_child['y_bootstrap'] + right_child['y_bootstrap']}\n",
    "        node['left_split'] = terminal_node(empty_child)\n",
    "        node['right_split'] = terminal_node(empty_child)\n",
    "        return\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        node['left_split'] = terminal_node(left_child)\n",
    "        node['right_split'] = terminal_node(right_child)\n",
    "        return node\n",
    "\n",
    "    if len(left_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['left_split'] = node['right_split'] = terminal_node(left_child)\n",
    "    else:\n",
    "        node['left_split'] = find_split_point(left_child['X_bootstrap'], left_child['y_bootstrap'], max_features)\n",
    "        split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
    "    if len(right_child['X_bootstrap']) <= min_samples_split:\n",
    "        node['right_split'] = node['left_split'] = terminal_node(right_child)\n",
    "    else:\n",
    "        node['right_split'] = find_split_point(right_child['X_bootstrap'], right_child['y_bootstrap'], max_features)\n",
    "        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):\n",
    "    root_node = find_split_point(X_bootstrap, y_bootstrap, max_features)\n",
    "    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
    "    return root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split):\n",
    "    tree_ls = list()\n",
    "    oob_ls = list()\n",
    "    for i in range(n_estimators):\n",
    "        X_bootstrap, y_bootstrap, X_oob, y_oob = draw_bootstrap(X_train, y_train)\n",
    "        tree = build_tree(X_bootstrap, y_bootstrap, max_features, max_depth, min_samples_split)\n",
    "        tree_ls.append(tree)\n",
    "        oob_error = oob_score(tree, X_oob, y_oob)\n",
    "        oob_ls.append(oob_error)\n",
    "    print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
    "    return tree_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(tree, X_test):\n",
    "    feature_idx = tree['feature_idx']\n",
    "\n",
    "    if X_test[feature_idx] <= tree['split_point']:\n",
    "        if type(tree['left_split']) == dict:\n",
    "            return predict_tree(tree['left_split'], X_test)\n",
    "        else:\n",
    "            value = tree['left_split']\n",
    "            return value\n",
    "    else:\n",
    "        if type(tree['right_split']) == dict:\n",
    "            return predict_tree(tree['right_split'], X_test)\n",
    "        else:\n",
    "            return tree['right_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rf(tree_ls, X_test):\n",
    "    pred_ls = list()\n",
    "    for i in range(len(X_test)):\n",
    "        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
    "        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
    "        pred_ls.append(final_pred)\n",
    "    return np.array(pred_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "max_features = 4\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "\n",
    "model = random_forest(X_train, y_train, n_estimators=10, max_features=4, max_depth=10, min_samples_split=2)\n",
    "preds = predict_rf(model, X_test)\n",
    "acc = sum(preds == y_test) / len(y_test)\n",
    "print(\"Testing accuracy: {}\".format(np.round(acc,3))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
