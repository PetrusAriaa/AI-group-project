{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"import pandas as pd\n",
				"import numpy as np\n",
				"import matplotlib.pyplot as plt\n",
				"import os\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"# read table\n",
				"\n",
				"dataPayment = '../Datasets/Employee_Payroll.csv'\n",
				"payroll = pd.read_csv(dataPayment)\n",
				"\n",
				"# set default value to 0 for NaN numerical data\n",
				"numeric_cols = payroll.select_dtypes(include=[np.number]).columns\n",
				"payroll[numeric_cols] = payroll[numeric_cols].clip(lower=0)\n",
				"\n",
				"\n",
				"payroll.fillna(0, inplace=True)\n",
				"payroll['Office'] = payroll['Office'].astype(int)\n",
				"\n",
				"# define column for 1/4 year discretization\n",
				"payroll['Fiscal Quarter'] = payroll['Fiscal Quarter']*0.25 - 0.25\n",
				"payroll['Fiscal Period'] = payroll['Fiscal Year'] + payroll['Fiscal Quarter']\n",
				"\n",
				"pd.to_datetime(payroll['Original Hire Date'])\n",
				"\n",
				"# parse hire date to get hire year\n",
				"payroll['Original Hire Date'] = payroll['Original Hire Date'].str.split('/').str[2]\n",
				"payroll['Original Hire Date'] = payroll['Original Hire Date'].astype(int)\n",
				"\n",
				"_work_year = payroll[\"Fiscal Period\"] - payroll['Original Hire Date']"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [],
			"source": [
				"# specify table column included\n",
				"\n",
				"payroll = payroll[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Job Title', 'Base Pay', 'Position ID', 'Employee Identifier']]\n",
				"\n",
				"# add Working Year Column\n",
				"payroll[\"Working Year\"] = _work_year"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [],
			"source": [
				"# YANG INI JANGAN DIJALANKAN DULU YA GESSS :'\n",
				"\n",
				"arr = []\n",
				"\n",
				"try:\n",
				"    with open('./cache/ids.txt', \"r\") as f:\n",
				"        for _id in f:\n",
				"            arr.append(int(_id))\n",
				"except:\n",
				"    if not os.path.exists('./cache'):\n",
				"        os.mkdir('./cache')\n",
				"        \n",
				"    _index = payroll['Job Code'].unique()\n",
				"    for _id in _index:\n",
				"        counts = len(payroll.groupby(['Job Code']).get_group(_id))\n",
				"        if counts > 1000:\n",
				"            arr.append(str(_id))\n",
				"    with open('cache/ids.txt', 'w') as f:\n",
				"        for _id in arr:\n",
				"            f.write('%s\\n' % _id)\n",
				"    with open('cache/ids.txt', 'r') as f:\n",
				"        arr = []\n",
				"        for _id in f:\n",
				"            arr.append(int(_id)) \n",
				"finally:\n",
				"   f.close()\n",
				"\n",
				"# :return : <List> arr : list of unique job id"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"2707"
						]
					},
					"execution_count": 8,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"emps = []\n",
				"max = 0;\n",
				"for _id in arr:\n",
				"    df = payroll[payroll['Job Code'] == _id]\n",
				"    emp_id = df['Employee Identifier'].unique()\n",
				"    if len(emp_id) > 50:\n",
				"        l = 75\n",
				"    else:\n",
				"        l = len(emp_id)\n",
				"\n",
				"    for i in range(l):\n",
				"        for i in range(100):\n",
				"            _index = np.random.randint(0, l-1)\n",
				"            if emp_id[_index] not in emps:\n",
				"                emps.append(emp_id[_index])\n",
				"                break\n",
				"\n",
				"\n",
				"len(emps)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>Fiscal Year</th>\n",
							"      <th>Fiscal Period</th>\n",
							"      <th>Job Code</th>\n",
							"      <th>Job Title</th>\n",
							"      <th>Base Pay</th>\n",
							"      <th>Position ID</th>\n",
							"      <th>Employee Identifier</th>\n",
							"      <th>Working Year</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.00</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>20088.00</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>11.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.25</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>23436.00</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>11.25</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.50</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>20422.82</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>11.50</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.75</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>23904.80</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>11.75</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.00</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>20745.80</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>12.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>...</th>\n",
							"      <td>...</td>\n",
							"      <td>...</td>\n",
							"      <td>...</td>\n",
							"      <td>...</td>\n",
							"      <td>...</td>\n",
							"      <td>...</td>\n",
							"      <td>...</td>\n",
							"      <td>...</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>234225</th>\n",
							"      <td>2018</td>\n",
							"      <td>2018.00</td>\n",
							"      <td>1570</td>\n",
							"      <td>Probation Officer II- PSB</td>\n",
							"      <td>13649.92</td>\n",
							"      <td>9514924</td>\n",
							"      <td>f01aa1fa-b791-4a57-b082-1de8559d5fba</td>\n",
							"      <td>34.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>234254</th>\n",
							"      <td>2018</td>\n",
							"      <td>2018.25</td>\n",
							"      <td>606</td>\n",
							"      <td>Assistant Public Defender III</td>\n",
							"      <td>30870.00</td>\n",
							"      <td>9511966</td>\n",
							"      <td>12c5ef30-094f-460d-98f6-3debea6853be</td>\n",
							"      <td>25.25</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>234259</th>\n",
							"      <td>2018</td>\n",
							"      <td>2018.00</td>\n",
							"      <td>48</td>\n",
							"      <td>Administrative Assistant III</td>\n",
							"      <td>17060.50</td>\n",
							"      <td>9513388</td>\n",
							"      <td>6ab6e3e3-8a44-4d22-8439-fee2ea9f9db6</td>\n",
							"      <td>25.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>234291</th>\n",
							"      <td>2018</td>\n",
							"      <td>2018.25</td>\n",
							"      <td>2051</td>\n",
							"      <td>Pharmacy Tech ARNTE</td>\n",
							"      <td>13964.56</td>\n",
							"      <td>903735</td>\n",
							"      <td>83c847da-1d2a-4a5c-b057-8cc02b2da114</td>\n",
							"      <td>4.25</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>234294</th>\n",
							"      <td>2018</td>\n",
							"      <td>2018.25</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>19001.95</td>\n",
							"      <td>9510048</td>\n",
							"      <td>ac4574b1-d301-44a7-a220-d3aafb5e9ec3</td>\n",
							"      <td>5.25</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"<p>24205 rows × 8 columns</p>\n",
							"</div>"
						],
						"text/plain": [
							"        Fiscal Year  Fiscal Period  Job Code                      Job Title  \\\n",
							"0              2016        2016.00      1172     Assistant State's Attorney   \n",
							"1              2016        2016.25      1172     Assistant State's Attorney   \n",
							"2              2016        2016.50      1172     Assistant State's Attorney   \n",
							"3              2016        2016.75      1172     Assistant State's Attorney   \n",
							"4              2017        2017.00      1172     Assistant State's Attorney   \n",
							"...             ...            ...       ...                            ...   \n",
							"234225         2018        2018.00      1570      Probation Officer II- PSB   \n",
							"234254         2018        2018.25       606  Assistant Public Defender III   \n",
							"234259         2018        2018.00        48   Administrative Assistant III   \n",
							"234291         2018        2018.25      2051            Pharmacy Tech ARNTE   \n",
							"234294         2018        2018.25      1172     Assistant State's Attorney   \n",
							"\n",
							"        Base Pay  Position ID                   Employee Identifier  \\\n",
							"0       20088.00      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c   \n",
							"1       23436.00      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c   \n",
							"2       20422.82      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c   \n",
							"3       23904.80      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c   \n",
							"4       20745.80      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c   \n",
							"...          ...          ...                                   ...   \n",
							"234225  13649.92      9514924  f01aa1fa-b791-4a57-b082-1de8559d5fba   \n",
							"234254  30870.00      9511966  12c5ef30-094f-460d-98f6-3debea6853be   \n",
							"234259  17060.50      9513388  6ab6e3e3-8a44-4d22-8439-fee2ea9f9db6   \n",
							"234291  13964.56       903735  83c847da-1d2a-4a5c-b057-8cc02b2da114   \n",
							"234294  19001.95      9510048  ac4574b1-d301-44a7-a220-d3aafb5e9ec3   \n",
							"\n",
							"        Working Year  \n",
							"0              11.00  \n",
							"1              11.25  \n",
							"2              11.50  \n",
							"3              11.75  \n",
							"4              12.00  \n",
							"...              ...  \n",
							"234225         34.00  \n",
							"234254         25.25  \n",
							"234259         25.00  \n",
							"234291          4.25  \n",
							"234294          5.25  \n",
							"\n",
							"[24205 rows x 8 columns]"
						]
					},
					"execution_count": 9,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"df_id = payroll[payroll['Employee Identifier'].isin(emps)]\n",
				"df_id"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [],
			"source": [
				"class RandomForestRegressor:\n",
				"    def __init__(self, n_estimators=10, max_depth=3, min_samples_split=2):\n",
				"        self.n_estimators = n_estimators\n",
				"        self.max_depth = max_depth\n",
				"        self.min_samples_split = min_samples_split\n",
				"        self.trees = []\n",
				"\n",
				"    def fit(self, X, y):\n",
				"        for i in range(self.n_estimators):\n",
				"            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
				"            idx = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
				"            tree.fit(X[idx], y[idx])\n",
				"            self.trees.append(tree)\n",
				"\n",
				"    def predict(self, X):\n",
				"        predictions = np.zeros((X.shape[0], len(self.trees)))\n",
				"        for i, tree in enumerate(self.trees):\n",
				"            predictions[:, i] = tree.predict(X)\n",
				"        return np.mean(predictions, axis=1)\n",
				"\n",
				"class DecisionTreeRegressor:\n",
				"    def __init__(self, max_depth=3, min_samples_split=2):\n",
				"        self.max_depth = max_depth\n",
				"        self.min_samples_split = min_samples_split\n",
				"        self.split_feature = None\n",
				"        self.split_value = None\n",
				"        self.left = None\n",
				"        self.right = None\n",
				"        self.prediction = None\n",
				"\n",
				"    def fit(self, X, y):\n",
				"        if self.max_depth == 0 or X.shape[0] < self.min_samples_split:\n",
				"            self.prediction = np.mean(y)\n",
				"            return\n",
				"        best_feature, best_value = self.find_best_split(X, y)\n",
				"        if best_feature is None or best_value is None:\n",
				"            self.prediction = np.mean(y)\n",
				"            return\n",
				"        self.split_feature = best_feature\n",
				"        self.split_value = best_value\n",
				"        left_idx = X[:, best_feature] < best_value\n",
				"        right_idx = X[:, best_feature] >= best_value\n",
				"        self.left = DecisionTreeRegressor(max_depth=self.max_depth-1, min_samples_split=self.min_samples_split)\n",
				"        self.left.fit(X[left_idx], y[left_idx])\n",
				"        self.right = DecisionTreeRegressor(max_depth=self.max_depth-1, min_samples_split=self.min_samples_split)\n",
				"        self.right.fit(X[right_idx], y[right_idx])\n",
				"\n",
				"    def find_best_split(self, X, y):\n",
				"        best_feature, best_value, best_variance_reduction = None, None, -float('inf')\n",
				"        for feature in range(X.shape[1]):\n",
				"            values = np.unique(X[:, feature])\n",
				"            if len(values) < 2:\n",
				"                continue\n",
				"            for value in values:\n",
				"                left_idx = X[:, feature] < value\n",
				"                right_idx = X[:, feature] >= value\n",
				"                if np.sum(left_idx) < self.min_samples_split or np.sum(right_idx) < self.min_samples_split:\n",
				"                    continue\n",
				"                left_variance = np.var(y[left_idx])\n",
				"                right_variance = np.var(y[right_idx])\n",
				"                total_variance = (np.sum(left_idx) * left_variance + np.sum(right_idx) * right_variance) / len(y)\n",
				"                variance_reduction = np.var(y) - total_variance\n",
				"                if variance_reduction > best_variance_reduction:\n",
				"                    best_feature = feature\n",
				"                    best_value = value\n",
				"                    best_variance_reduction = variance_reduction\n",
				"        return best_feature, best_value\n",
				"\n",
				"    def predict(self, X):\n",
				"        if self.prediction is not None:\n",
				"            return np.full((X.shape[0],), self.prediction)\n",
				"        left_idx = X[:, self.split_feature] < self.split_value\n",
				"        right_idx = X[:, self.split_feature] >= self.split_value\n",
				"        predictions = np.zeros((X.shape[0],))\n",
				"        predictions[left_idx] = self.left.predict(X[left_idx])\n",
				"        predictions[right_idx] = self.right.predict(X[right_idx])\n",
				"        return predictions"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"from sklearn.model_selection import train_test_split"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import random"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"#X = payroll[['Job Code','Working Year']]\n",
				"#Y = payroll['Base Pay']\n",
				"#X.head(10)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"#X_train, X_test,y_train,y_test = train_test_split(X,Y,test_size =0.2)\n",
				"# print the data\n",
				"#X_train"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Extracting the features & manually splitting the dataset & selecting survived as our target variable\n",
				"features = ['Job Code', 'Working Year', 'Position ID', 'Fiscal Period', 'Fiscal Year']\n",
				"nb_train = int(np.floor(0.8 * len(payroll)))\n",
				"df = payroll.sample(frac=1, random_state=217)\n",
				"X_train = df[features][:nb_train]\n",
				"y_train = df['Base Pay'][:nb_train].values\n",
				"X_test = df[features][nb_train:]\n",
				"y_test = df['Base Pay'][nb_train:].values"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Defining a function for calculating the entropy\n",
				"def entropy(p): \n",
				"    if p == 0:\n",
				"        return 0\n",
				"    elif p == 1:\n",
				"        return 0\n",
				"    else:\n",
				"        return - (p * np.log2(p) + (1 - p) * np.log2(1-p))\n",
				"\n",
				"# defining a function to calculate information gain of the decision tree\n",
				"def information_gain(left_child, right_child): \n",
				"    parent = left_child + right_child\n",
				"    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
				"    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
				"    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
				"    IG_p = entropy(p_parent)\n",
				"    IG_l = entropy(p_left)\n",
				"    IG_r = entropy(p_right)\n",
				"    return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def draw_bootstrap(X_train, y_train): # Function for calculating the bootstrap for drawing the branches\n",
				"    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
				"    oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
				"    X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
				"    y_bootstrap = y_train[bootstrap_indices]\n",
				"    X_oob = X_train.iloc[oob_indices].values\n",
				"    y_oob = y_train[oob_indices]\n",
				"    return X_bootstrap, y_bootstrap, X_oob, y_oob\n",
				"\n",
				"def oob_score(tree, X_test, y_test): # Function for checking the out of block(test dataset) & determine the score\n",
				"    mis_label = 0\n",
				"    for i in range(len(X_test)):\n",
				"        pred = predict_tree(tree, X_test[i])\n",
				"        if pred != y_test[i]:\n",
				"            mis_label += 1\n",
				"    return mis_label / len(X_test)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def find_split_point(X_bootstrap, y_bootstrap, max_features):# Function for caclculating the number of split\n",
				"    feature_ls = list()\n",
				"    num_features = len(X_bootstrap[0])\n",
				"\n",
				"    while len(feature_ls) <= max_features:\n",
				"      feature_idx = random.sample(range(num_features), 1)\n",
				"      if feature_idx not in feature_ls:\n",
				"        feature_ls.extend(feature_idx)\n",
				"\n",
				"    best_info_gain = -999\n",
				"    node = None\n",
				"    for feature_idx in feature_ls:\n",
				"      for split_point in X_bootstrap[:,feature_idx]:\n",
				"        left_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
				"        right_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
				"\n",
				"        # split children for continuous variables\n",
				"        if type(split_point) in [int, float]:\n",
				"            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
				"                if value <= split_point:\n",
				"                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
				"                    left_child['y_bootstrap'].append(y_bootstrap[i])\n",
				"                else:\n",
				"                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
				"                    right_child['y_bootstrap'].append(y_bootstrap[i])\n",
				"        # split children for categoric variables\n",
				"        else:\n",
				"            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
				"                if value == split_point:\n",
				"                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
				"                    left_child['y_bootstrap'].append(y_bootstrap[i])\n",
				"                else:\n",
				"                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
				"                    right_child['y_bootstrap'].append(y_bootstrap[i])\n",
				"\n",
				"        split_info_gain = information_gain(left_child['y_bootstrap'], right_child['y_bootstrap'])\n",
				"        if split_info_gain > best_info_gain:\n",
				"            best_info_gain = split_info_gain\n",
				"            left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
				"            right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
				"            node = {'information_gain': split_info_gain,\n",
				"                    'left_child': left_child,\n",
				"                    'right_child': right_child,\n",
				"                    'split_point': split_point,\n",
				"                    'feature_idx': feature_idx}\n",
				"\n",
				"\n",
				"    return node"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def terminal_node(node):# Function for the terminal node of the decision tree\n",
				"    y_bootstrap = node['y_bootstrap']\n",
				"    pred = max(y_bootstrap, key = y_bootstrap.count)\n",
				"    return pred\n",
				"\n",
				"\n",
				"def split_node(node, max_features, min_samples_split, max_depth, depth):# function for including all the hyperparameters\n",
				"    left_child = node['left_child']\n",
				"    right_child = node['right_child']\n",
				"\n",
				"    del(node['left_child'])\n",
				"    del(node['right_child'])\n",
				"\n",
				"    if len(left_child['y_bootstrap']) == 0 or len(right_child['y_bootstrap']) == 0:\n",
				"        empty_child = {'y_bootstrap': left_child['y_bootstrap'] + right_child['y_bootstrap']}\n",
				"        node['left_split'] = terminal_node(empty_child)\n",
				"        node['right_split'] = terminal_node(empty_child)\n",
				"        return\n",
				"\n",
				"    if depth >= max_depth:\n",
				"        node['left_split'] = terminal_node(left_child)\n",
				"        node['right_split'] = terminal_node(right_child)\n",
				"        return node\n",
				"\n",
				"    if len(left_child['X_bootstrap']) <= min_samples_split:\n",
				"        node['left_split'] = node['right_split'] = terminal_node(left_child)\n",
				"    else:\n",
				"        node['left_split'] = find_split_point(left_child['X_bootstrap'], left_child['y_bootstrap'], max_features)\n",
				"        split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
				"    if len(right_child['X_bootstrap']) <= min_samples_split:\n",
				"        node['right_split'] = node['left_split'] = terminal_node(right_child)\n",
				"    else:\n",
				"        node['right_split'] = find_split_point(right_child['X_bootstrap'], right_child['y_bootstrap'], max_features)\n",
				"        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def build_tree(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):# Function for building of the tree\n",
				"    root_node = find_split_point(X_bootstrap, y_bootstrap, max_features)\n",
				"    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
				"    return root_node\n",
				"\n",
				"def random_forest(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split):# Function to use Random Forest Regressor\n",
				"    tree_ls = list()\n",
				"    oob_ls = list()\n",
				"    for i in range(n_estimators):\n",
				"        X_bootstrap, y_bootstrap, X_oob, y_oob = draw_bootstrap(X_train, y_train)\n",
				"        tree = build_tree(X_bootstrap, y_bootstrap, max_features, max_depth, min_samples_split)\n",
				"        tree_ls.append(tree)\n",
				"        oob_error = oob_score(tree, X_oob, y_oob)\n",
				"        oob_ls.append(oob_error)\n",
				"    print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
				"    return tree_ls"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def predict_tree(tree, X_test):# Function for predictions of trees\n",
				"    feature_idx = tree['feature_idx']\n",
				"\n",
				"    if X_test[feature_idx] <= tree['split_point']:\n",
				"        if type(tree['left_split']) == dict:\n",
				"            return predict_tree(tree['left_split'], X_test)\n",
				"        else:\n",
				"            value = tree['left_split']\n",
				"            return value\n",
				"    else:\n",
				"        if type(tree['right_split']) == dict:\n",
				"            return predict_tree(tree['right_split'], X_test)\n",
				"        else:\n",
				"            return tree['right_split']"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def predict_rf(tree_ls, X_test):# function for prediction of random forest\n",
				"    pred_ls = list()\n",
				"    for i in range(len(X_test)):\n",
				"        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
				"        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
				"        pred_ls.append(final_pred)\n",
				"    return np.array(pred_ls)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Manual Tuning of the hyperparameters\n",
				"n_estimators = 50\n",
				"max_features = 5\n",
				"max_depth = 10\n",
				"min_samples_split = 2\n",
				"\n",
				"model = random_forest(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [
				{
					"ename": "NameError",
					"evalue": "name 'model' is not defined",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
						"Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# predicting the accuracy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m preds \u001b[39m=\u001b[39m predict_rf(model, X_test)\n\u001b[0;32m      3\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(preds \u001b[39m==\u001b[39m y_test) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_test)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTesting accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39mround(acc,\u001b[39m3\u001b[39m)))\n",
						"\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
					]
				}
			],
			"source": [
				"# predicting the accuracy\n",
				"preds = predict_rf(model, X_test)\n",
				"acc = sum(preds == y_test) / len(y_test)\n",
				"print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# YANG INI JANGAN DIJALANKAN DULU YA GESSS :'\n",
				"\n",
				"#arr = []\n",
				"\n",
				"#try:\n",
				"    #with open('./cache/ids.txt', \"r\") as f:\n",
				"        #for _id in f:\n",
				"            #arr.append(int(_id))\n",
				"#except:\n",
				"    #if not os.path.exists('./cache'):\n",
				"        #os.mkdir('./cache')\n",
				"        \n",
				"    #_index = payroll['Job Code'].unique()\n",
				"    #for _id in _index:\n",
				"        #counts = len(payroll.groupby(['Job Code']).get_group(_id))\n",
				"        #if counts > 1000:\n",
				"            #arr.append(str(_id))\n",
				"    #with open('cache/ids.txt', 'w') as f:\n",
				"        #for _id in arr:\n",
				"            #f.write('%s\\n' % _id) \n",
				"#finally:\n",
				"   #f.close()\n",
				"\n",
				"# :return : <List> arr : list of unique job id"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Group Job Code 1172 training dataset <<< PAKAI INI NGGIH\n",
				"\n",
				"#group_1172 = payroll.groupby(['Job Code']).get_group(1172)\n",
				"\n",
				"#_sorted = group_1172.sort_values('Employee Identifier')\n",
				"#fiscal = pd.pivot_table(_sorted, values='Base Pay', index=['Fiscal Period'], columns='Employee Identifier')\n",
				"\n",
				"#fiscal = fiscal.diff()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# cleaned display table\n",
				"\n",
				"#fiscal.fillna(0, inplace=True)\n",
				"#fiscal = fiscal.drop(2016.00)\n",
				"\n",
				"#fiscal"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"\n",
				"\n",
				"# neg_cols = (payroll[numeric_cols] < 0).any()\n",
				"\n",
				"# if neg_cols.any():\n",
				"#     print(\"Terdapat nilai negatif pada kolom: \", end=\"\")\n",
				"#     print(\", \".join(neg_cols[neg_cols == True].index))\n",
				"# else:\n",
				"#     print(\"Tidak terdapat nilai negatif pada semua kolom numerik.\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# SUDAH AMAN 👍👍\n",
				"\n",
				"# null_cols = payroll.isnull().any()\n",
				"\n",
				"# if null_cols.any():\n",
				"#     print(\"Terdapat nilai NaN pada kolom: \", end=\"\")\n",
				"#     print(\", \".join(null_cols[null_cols == True].index))\n",
				"# else:\n",
				"#     print(\"Tidak terdapat nilai NaN pada semua kolom.\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# query job code indexing\n",
				"\n",
				"#for val in arr:\n",
				"    #new_df = payroll[payroll['Job Code'] == val]\n",
				"    #print(f\"DataFrame for job code {val}:\")\n",
				"    #display(new_df)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.8"
		},
		"orig_nbformat": 4
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
