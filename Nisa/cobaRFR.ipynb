{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"import pandas as pd\n",
				"import numpy as np\n",
				"import matplotlib.pyplot as plt\n",
				"import os\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"# read table\n",
				"\n",
				"dataPayment = '../Datasets/Employee_Payroll.csv'\n",
				"payroll = pd.read_csv(dataPayment)\n",
				"\n",
				"# set default value to 0 for NaN numerical data\n",
				"numeric_cols = payroll.select_dtypes(include=[np.number]).columns\n",
				"payroll[numeric_cols] = payroll[numeric_cols].clip(lower=0)\n",
				"\n",
				"\n",
				"payroll.fillna(0, inplace=True)\n",
				"payroll['Office'] = payroll['Office'].astype(int)\n",
				"\n",
				"# define column for 1/4 year discretization\n",
				"payroll['Fiscal Quarter'] = payroll['Fiscal Quarter']*0.25 - 0.25\n",
				"payroll['Fiscal Period'] = payroll['Fiscal Year'] + payroll['Fiscal Quarter']\n",
				"\n",
				"pd.to_datetime(payroll['Original Hire Date'])\n",
				"\n",
				"# parse hire date to get hire year\n",
				"payroll['Original Hire Date'] = payroll['Original Hire Date'].str.split('/').str[2]\n",
				"payroll['Original Hire Date'] = payroll['Original Hire Date'].astype(int)\n",
				"\n",
				"_work_year = payroll[\"Fiscal Period\"] - payroll['Original Hire Date']"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>Fiscal Year</th>\n",
							"      <th>Fiscal Period</th>\n",
							"      <th>Job Code</th>\n",
							"      <th>Job Title</th>\n",
							"      <th>Base Pay</th>\n",
							"      <th>Position ID</th>\n",
							"      <th>Employee Identifier</th>\n",
							"      <th>Working Year</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.00</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>20088.00</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>11.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.25</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>23436.00</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>11.25</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.50</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>20422.82</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>11.50</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.75</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>23904.80</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>11.75</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.00</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>20745.80</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>12.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>5</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.25</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>24473.38</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>12.25</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>6</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.50</td>\n",
							"      <td>1172</td>\n",
							"      <td>Assistant State's Attorney</td>\n",
							"      <td>21217.35</td>\n",
							"      <td>9510200</td>\n",
							"      <td>6ac7ba3e-d286-44f5-87a0-191dc415e23c</td>\n",
							"      <td>12.50</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>7</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.00</td>\n",
							"      <td>5049</td>\n",
							"      <td>Residential Model Sr Anal III</td>\n",
							"      <td>17770.86</td>\n",
							"      <td>9500731</td>\n",
							"      <td>f313b1c3-1b1a-4b07-bb75-a8c850a91bac</td>\n",
							"      <td>18.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>8</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.25</td>\n",
							"      <td>5049</td>\n",
							"      <td>Residential Model Sr Anal III</td>\n",
							"      <td>20800.67</td>\n",
							"      <td>9500731</td>\n",
							"      <td>f313b1c3-1b1a-4b07-bb75-a8c850a91bac</td>\n",
							"      <td>18.25</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>9</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.50</td>\n",
							"      <td>5049</td>\n",
							"      <td>Residential Model Sr Anal III</td>\n",
							"      <td>17873.76</td>\n",
							"      <td>9500731</td>\n",
							"      <td>f313b1c3-1b1a-4b07-bb75-a8c850a91bac</td>\n",
							"      <td>18.50</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>10</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.75</td>\n",
							"      <td>5049</td>\n",
							"      <td>Residential Model Sr Anal III</td>\n",
							"      <td>20904.80</td>\n",
							"      <td>9500731</td>\n",
							"      <td>f313b1c3-1b1a-4b07-bb75-a8c850a91bac</td>\n",
							"      <td>18.75</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>11</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.00</td>\n",
							"      <td>5049</td>\n",
							"      <td>Residential Model Sr Anal III</td>\n",
							"      <td>18254.40</td>\n",
							"      <td>9500731</td>\n",
							"      <td>f313b1c3-1b1a-4b07-bb75-a8c850a91bac</td>\n",
							"      <td>19.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>12</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.25</td>\n",
							"      <td>5049</td>\n",
							"      <td>Residential Model Sr Anal III</td>\n",
							"      <td>21375.20</td>\n",
							"      <td>9500731</td>\n",
							"      <td>f313b1c3-1b1a-4b07-bb75-a8c850a91bac</td>\n",
							"      <td>19.25</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>13</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.50</td>\n",
							"      <td>5049</td>\n",
							"      <td>Residential Model Sr Anal III</td>\n",
							"      <td>18626.76</td>\n",
							"      <td>9500731</td>\n",
							"      <td>f313b1c3-1b1a-4b07-bb75-a8c850a91bac</td>\n",
							"      <td>19.50</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>14</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.75</td>\n",
							"      <td>5049</td>\n",
							"      <td>Residential Model Sr Anal III</td>\n",
							"      <td>21802.46</td>\n",
							"      <td>9500731</td>\n",
							"      <td>f313b1c3-1b1a-4b07-bb75-a8c850a91bac</td>\n",
							"      <td>19.75</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>15</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.00</td>\n",
							"      <td>1642</td>\n",
							"      <td>Attending Physician XII</td>\n",
							"      <td>57692.40</td>\n",
							"      <td>1100069</td>\n",
							"      <td>f888af25-5b0d-457a-83cc-3415f03ed7c6</td>\n",
							"      <td>3.00</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>16</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.25</td>\n",
							"      <td>1642</td>\n",
							"      <td>Attending Physician XII</td>\n",
							"      <td>67307.80</td>\n",
							"      <td>1100069</td>\n",
							"      <td>f888af25-5b0d-457a-83cc-3415f03ed7c6</td>\n",
							"      <td>3.25</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>17</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.50</td>\n",
							"      <td>1642</td>\n",
							"      <td>Attending Physician XII</td>\n",
							"      <td>57692.40</td>\n",
							"      <td>1100069</td>\n",
							"      <td>f888af25-5b0d-457a-83cc-3415f03ed7c6</td>\n",
							"      <td>3.50</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>18</th>\n",
							"      <td>2016</td>\n",
							"      <td>2016.75</td>\n",
							"      <td>1642</td>\n",
							"      <td>Attending Physician XII</td>\n",
							"      <td>67307.80</td>\n",
							"      <td>1100069</td>\n",
							"      <td>f888af25-5b0d-457a-83cc-3415f03ed7c6</td>\n",
							"      <td>3.75</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>19</th>\n",
							"      <td>2017</td>\n",
							"      <td>2017.00</td>\n",
							"      <td>1642</td>\n",
							"      <td>Attending Physician XII</td>\n",
							"      <td>57692.28</td>\n",
							"      <td>1100069</td>\n",
							"      <td>f888af25-5b0d-457a-83cc-3415f03ed7c6</td>\n",
							"      <td>4.00</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"    Fiscal Year  Fiscal Period  Job Code                      Job Title  \\\n",
							"0          2016        2016.00      1172     Assistant State's Attorney   \n",
							"1          2016        2016.25      1172     Assistant State's Attorney   \n",
							"2          2016        2016.50      1172     Assistant State's Attorney   \n",
							"3          2016        2016.75      1172     Assistant State's Attorney   \n",
							"4          2017        2017.00      1172     Assistant State's Attorney   \n",
							"5          2017        2017.25      1172     Assistant State's Attorney   \n",
							"6          2017        2017.50      1172     Assistant State's Attorney   \n",
							"7          2016        2016.00      5049  Residential Model Sr Anal III   \n",
							"8          2016        2016.25      5049  Residential Model Sr Anal III   \n",
							"9          2016        2016.50      5049  Residential Model Sr Anal III   \n",
							"10         2016        2016.75      5049  Residential Model Sr Anal III   \n",
							"11         2017        2017.00      5049  Residential Model Sr Anal III   \n",
							"12         2017        2017.25      5049  Residential Model Sr Anal III   \n",
							"13         2017        2017.50      5049  Residential Model Sr Anal III   \n",
							"14         2017        2017.75      5049  Residential Model Sr Anal III   \n",
							"15         2016        2016.00      1642        Attending Physician XII   \n",
							"16         2016        2016.25      1642        Attending Physician XII   \n",
							"17         2016        2016.50      1642        Attending Physician XII   \n",
							"18         2016        2016.75      1642        Attending Physician XII   \n",
							"19         2017        2017.00      1642        Attending Physician XII   \n",
							"\n",
							"    Base Pay  Position ID                   Employee Identifier  Working Year  \n",
							"0   20088.00      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c         11.00  \n",
							"1   23436.00      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c         11.25  \n",
							"2   20422.82      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c         11.50  \n",
							"3   23904.80      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c         11.75  \n",
							"4   20745.80      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c         12.00  \n",
							"5   24473.38      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c         12.25  \n",
							"6   21217.35      9510200  6ac7ba3e-d286-44f5-87a0-191dc415e23c         12.50  \n",
							"7   17770.86      9500731  f313b1c3-1b1a-4b07-bb75-a8c850a91bac         18.00  \n",
							"8   20800.67      9500731  f313b1c3-1b1a-4b07-bb75-a8c850a91bac         18.25  \n",
							"9   17873.76      9500731  f313b1c3-1b1a-4b07-bb75-a8c850a91bac         18.50  \n",
							"10  20904.80      9500731  f313b1c3-1b1a-4b07-bb75-a8c850a91bac         18.75  \n",
							"11  18254.40      9500731  f313b1c3-1b1a-4b07-bb75-a8c850a91bac         19.00  \n",
							"12  21375.20      9500731  f313b1c3-1b1a-4b07-bb75-a8c850a91bac         19.25  \n",
							"13  18626.76      9500731  f313b1c3-1b1a-4b07-bb75-a8c850a91bac         19.50  \n",
							"14  21802.46      9500731  f313b1c3-1b1a-4b07-bb75-a8c850a91bac         19.75  \n",
							"15  57692.40      1100069  f888af25-5b0d-457a-83cc-3415f03ed7c6          3.00  \n",
							"16  67307.80      1100069  f888af25-5b0d-457a-83cc-3415f03ed7c6          3.25  \n",
							"17  57692.40      1100069  f888af25-5b0d-457a-83cc-3415f03ed7c6          3.50  \n",
							"18  67307.80      1100069  f888af25-5b0d-457a-83cc-3415f03ed7c6          3.75  \n",
							"19  57692.28      1100069  f888af25-5b0d-457a-83cc-3415f03ed7c6          4.00  "
						]
					},
					"execution_count": 3,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"# specify table column included\n",
				"\n",
				"payroll = payroll[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Job Title', 'Base Pay', 'Position ID', 'Employee Identifier']]\n",
				"\n",
				"# add Working Year Column\n",
				"payroll[\"Working Year\"] = _work_year\n",
				"\n",
				"payroll.head(20)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [],
			"source": [
				"class RandomForestRegressor:\n",
				"    def __init__(self, n_estimators=10, max_depth=3, min_samples_split=2):\n",
				"        self.n_estimators = n_estimators\n",
				"        self.max_depth = max_depth\n",
				"        self.min_samples_split = min_samples_split\n",
				"        self.trees = []\n",
				"\n",
				"    def fit(self, X, y):\n",
				"        for i in range(self.n_estimators):\n",
				"            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
				"            idx = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
				"            tree.fit(X[idx], y[idx])\n",
				"            self.trees.append(tree)\n",
				"\n",
				"    def predict(self, X):\n",
				"        predictions = np.zeros((X.shape[0], len(self.trees)))\n",
				"        for i, tree in enumerate(self.trees):\n",
				"            predictions[:, i] = tree.predict(X)\n",
				"        return np.mean(predictions, axis=1)\n",
				"\n",
				"class DecisionTreeRegressor:\n",
				"    def __init__(self, max_depth=3, min_samples_split=2):\n",
				"        self.max_depth = max_depth\n",
				"        self.min_samples_split = min_samples_split\n",
				"        self.split_feature = None\n",
				"        self.split_value = None\n",
				"        self.left = None\n",
				"        self.right = None\n",
				"        self.prediction = None\n",
				"\n",
				"    def fit(self, X, y):\n",
				"        if self.max_depth == 0 or X.shape[0] < self.min_samples_split:\n",
				"            self.prediction = np.mean(y)\n",
				"            return\n",
				"        best_feature, best_value = self.find_best_split(X, y)\n",
				"        if best_feature is None or best_value is None:\n",
				"            self.prediction = np.mean(y)\n",
				"            return\n",
				"        self.split_feature = best_feature\n",
				"        self.split_value = best_value\n",
				"        left_idx = X[:, best_feature] < best_value\n",
				"        right_idx = X[:, best_feature] >= best_value\n",
				"        self.left = DecisionTreeRegressor(max_depth=self.max_depth-1, min_samples_split=self.min_samples_split)\n",
				"        self.left.fit(X[left_idx], y[left_idx])\n",
				"        self.right = DecisionTreeRegressor(max_depth=self.max_depth-1, min_samples_split=self.min_samples_split)\n",
				"        self.right.fit(X[right_idx], y[right_idx])\n",
				"\n",
				"    def find_best_split(self, X, y):\n",
				"        best_feature, best_value, best_variance_reduction = None, None, -float('inf')\n",
				"        for feature in range(X.shape[1]):\n",
				"            values = np.unique(X[:, feature])\n",
				"            if len(values) < 2:\n",
				"                continue\n",
				"            for value in values:\n",
				"                left_idx = X[:, feature] < value\n",
				"                right_idx = X[:, feature] >= value\n",
				"                if np.sum(left_idx) < self.min_samples_split or np.sum(right_idx) < self.min_samples_split:\n",
				"                    continue\n",
				"                left_variance = np.var(y[left_idx])\n",
				"                right_variance = np.var(y[right_idx])\n",
				"                total_variance = (np.sum(left_idx) * left_variance + np.sum(right_idx) * right_variance) / len(y)\n",
				"                variance_reduction = np.var(y) - total_variance\n",
				"                if variance_reduction > best_variance_reduction:\n",
				"                    best_feature = feature\n",
				"                    best_value = value\n",
				"                    best_variance_reduction = variance_reduction\n",
				"        return best_feature, best_value\n",
				"\n",
				"    def predict(self, X):\n",
				"        if self.prediction is not None:\n",
				"            return np.full((X.shape[0],), self.prediction)\n",
				"        left_idx = X[:, self.split_feature] < self.split_value\n",
				"        right_idx = X[:, self.split_feature] >= self.split_value\n",
				"        predictions = np.zeros((X.shape[0],))\n",
				"        predictions[left_idx] = self.left.predict(X[left_idx])\n",
				"        predictions[right_idx] = self.right.predict(X[right_idx])\n",
				"        return predictions"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"from sklearn.model_selection import train_test_split"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import random"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"#X = payroll[['Job Code','Working Year']]\n",
				"#Y = payroll['Base Pay']\n",
				"#X.head(10)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"#X_train, X_test,y_train,y_test = train_test_split(X,Y,test_size =0.2)\n",
				"# print the data\n",
				"#X_train"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Extracting the features & manually splitting the dataset & selecting survived as our target variable\n",
				"features = ['Job Code', 'Working Year', 'Position ID', 'Fiscal Period', 'Fiscal Year']\n",
				"nb_train = int(np.floor(0.8 * len(payroll)))\n",
				"df = payroll.sample(frac=1, random_state=217)\n",
				"X_train = df[features][:nb_train]\n",
				"y_train = df['Base Pay'][:nb_train].values\n",
				"X_test = df[features][nb_train:]\n",
				"y_test = df['Base Pay'][nb_train:].values"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Defining a function for calculating the entropy\n",
				"def entropy(p): \n",
				"    if p == 0:\n",
				"        return 0\n",
				"    elif p == 1:\n",
				"        return 0\n",
				"    else:\n",
				"        return - (p * np.log2(p) + (1 - p) * np.log2(1-p))\n",
				"\n",
				"# defining a function to calculate information gain of the decision tree\n",
				"def information_gain(left_child, right_child): \n",
				"    parent = left_child + right_child\n",
				"    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
				"    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
				"    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
				"    IG_p = entropy(p_parent)\n",
				"    IG_l = entropy(p_left)\n",
				"    IG_r = entropy(p_right)\n",
				"    return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def draw_bootstrap(X_train, y_train): # Function for calculating the bootstrap for drawing the branches\n",
				"    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
				"    oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
				"    X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
				"    y_bootstrap = y_train[bootstrap_indices]\n",
				"    X_oob = X_train.iloc[oob_indices].values\n",
				"    y_oob = y_train[oob_indices]\n",
				"    return X_bootstrap, y_bootstrap, X_oob, y_oob\n",
				"\n",
				"def oob_score(tree, X_test, y_test): # Function for checking the out of block(test dataset) & determine the score\n",
				"    mis_label = 0\n",
				"    for i in range(len(X_test)):\n",
				"        pred = predict_tree(tree, X_test[i])\n",
				"        if pred != y_test[i]:\n",
				"            mis_label += 1\n",
				"    return mis_label / len(X_test)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def find_split_point(X_bootstrap, y_bootstrap, max_features):# Function for caclculating the number of split\n",
				"    feature_ls = list()\n",
				"    num_features = len(X_bootstrap[0])\n",
				"\n",
				"    while len(feature_ls) <= max_features:\n",
				"      feature_idx = random.sample(range(num_features), 1)\n",
				"      if feature_idx not in feature_ls:\n",
				"        feature_ls.extend(feature_idx)\n",
				"\n",
				"    best_info_gain = -999\n",
				"    node = None\n",
				"    for feature_idx in feature_ls:\n",
				"      for split_point in X_bootstrap[:,feature_idx]:\n",
				"        left_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
				"        right_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
				"\n",
				"        # split children for continuous variables\n",
				"        if type(split_point) in [int, float]:\n",
				"            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
				"                if value <= split_point:\n",
				"                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
				"                    left_child['y_bootstrap'].append(y_bootstrap[i])\n",
				"                else:\n",
				"                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
				"                    right_child['y_bootstrap'].append(y_bootstrap[i])\n",
				"        # split children for categoric variables\n",
				"        else:\n",
				"            for i, value in enumerate(X_bootstrap[:,feature_idx]):\n",
				"                if value == split_point:\n",
				"                    left_child['X_bootstrap'].append(X_bootstrap[i])\n",
				"                    left_child['y_bootstrap'].append(y_bootstrap[i])\n",
				"                else:\n",
				"                    right_child['X_bootstrap'].append(X_bootstrap[i])\n",
				"                    right_child['y_bootstrap'].append(y_bootstrap[i])\n",
				"\n",
				"        split_info_gain = information_gain(left_child['y_bootstrap'], right_child['y_bootstrap'])\n",
				"        if split_info_gain > best_info_gain:\n",
				"            best_info_gain = split_info_gain\n",
				"            left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
				"            right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
				"            node = {'information_gain': split_info_gain,\n",
				"                    'left_child': left_child,\n",
				"                    'right_child': right_child,\n",
				"                    'split_point': split_point,\n",
				"                    'feature_idx': feature_idx}\n",
				"\n",
				"\n",
				"    return node"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def terminal_node(node):# Function for the terminal node of the decision tree\n",
				"    y_bootstrap = node['y_bootstrap']\n",
				"    pred = max(y_bootstrap, key = y_bootstrap.count)\n",
				"    return pred\n",
				"\n",
				"\n",
				"def split_node(node, max_features, min_samples_split, max_depth, depth):# function for including all the hyperparameters\n",
				"    left_child = node['left_child']\n",
				"    right_child = node['right_child']\n",
				"\n",
				"    del(node['left_child'])\n",
				"    del(node['right_child'])\n",
				"\n",
				"    if len(left_child['y_bootstrap']) == 0 or len(right_child['y_bootstrap']) == 0:\n",
				"        empty_child = {'y_bootstrap': left_child['y_bootstrap'] + right_child['y_bootstrap']}\n",
				"        node['left_split'] = terminal_node(empty_child)\n",
				"        node['right_split'] = terminal_node(empty_child)\n",
				"        return\n",
				"\n",
				"    if depth >= max_depth:\n",
				"        node['left_split'] = terminal_node(left_child)\n",
				"        node['right_split'] = terminal_node(right_child)\n",
				"        return node\n",
				"\n",
				"    if len(left_child['X_bootstrap']) <= min_samples_split:\n",
				"        node['left_split'] = node['right_split'] = terminal_node(left_child)\n",
				"    else:\n",
				"        node['left_split'] = find_split_point(left_child['X_bootstrap'], left_child['y_bootstrap'], max_features)\n",
				"        split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
				"    if len(right_child['X_bootstrap']) <= min_samples_split:\n",
				"        node['right_split'] = node['left_split'] = terminal_node(right_child)\n",
				"    else:\n",
				"        node['right_split'] = find_split_point(right_child['X_bootstrap'], right_child['y_bootstrap'], max_features)\n",
				"        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def build_tree(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):# Function for building of the tree\n",
				"    root_node = find_split_point(X_bootstrap, y_bootstrap, max_features)\n",
				"    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
				"    return root_node\n",
				"\n",
				"def random_forest(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split):# Function to use Random Forest Regressor\n",
				"    tree_ls = list()\n",
				"    oob_ls = list()\n",
				"    for i in range(n_estimators):\n",
				"        X_bootstrap, y_bootstrap, X_oob, y_oob = draw_bootstrap(X_train, y_train)\n",
				"        tree = build_tree(X_bootstrap, y_bootstrap, max_features, max_depth, min_samples_split)\n",
				"        tree_ls.append(tree)\n",
				"        oob_error = oob_score(tree, X_oob, y_oob)\n",
				"        oob_ls.append(oob_error)\n",
				"    print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
				"    return tree_ls"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def predict_tree(tree, X_test):# Function for predictions of trees\n",
				"    feature_idx = tree['feature_idx']\n",
				"\n",
				"    if X_test[feature_idx] <= tree['split_point']:\n",
				"        if type(tree['left_split']) == dict:\n",
				"            return predict_tree(tree['left_split'], X_test)\n",
				"        else:\n",
				"            value = tree['left_split']\n",
				"            return value\n",
				"    else:\n",
				"        if type(tree['right_split']) == dict:\n",
				"            return predict_tree(tree['right_split'], X_test)\n",
				"        else:\n",
				"            return tree['right_split']"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def predict_rf(tree_ls, X_test):# function for prediction of random forest\n",
				"    pred_ls = list()\n",
				"    for i in range(len(X_test)):\n",
				"        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
				"        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
				"        pred_ls.append(final_pred)\n",
				"    return np.array(pred_ls)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Manual Tuning of the hyperparameters\n",
				"n_estimators = 50\n",
				"max_features = 5\n",
				"max_depth = 10\n",
				"min_samples_split = 2\n",
				"\n",
				"model = random_forest(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [
				{
					"ename": "NameError",
					"evalue": "name 'model' is not defined",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
						"Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# predicting the accuracy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m preds \u001b[39m=\u001b[39m predict_rf(model, X_test)\n\u001b[0;32m      3\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(preds \u001b[39m==\u001b[39m y_test) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_test)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTesting accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39mround(acc,\u001b[39m3\u001b[39m)))\n",
						"\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
					]
				}
			],
			"source": [
				"# predicting the accuracy\n",
				"preds = predict_rf(model, X_test)\n",
				"acc = sum(preds == y_test) / len(y_test)\n",
				"print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# YANG INI JANGAN DIJALANKAN DULU YA GESSS :'\n",
				"\n",
				"#arr = []\n",
				"\n",
				"#try:\n",
				"    #with open('./cache/ids.txt', \"r\") as f:\n",
				"        #for _id in f:\n",
				"            #arr.append(int(_id))\n",
				"#except:\n",
				"    #if not os.path.exists('./cache'):\n",
				"        #os.mkdir('./cache')\n",
				"        \n",
				"    #_index = payroll['Job Code'].unique()\n",
				"    #for _id in _index:\n",
				"        #counts = len(payroll.groupby(['Job Code']).get_group(_id))\n",
				"        #if counts > 1000:\n",
				"            #arr.append(str(_id))\n",
				"    #with open('cache/ids.txt', 'w') as f:\n",
				"        #for _id in arr:\n",
				"            #f.write('%s\\n' % _id) \n",
				"#finally:\n",
				"   #f.close()\n",
				"\n",
				"# :return : <List> arr : list of unique job id"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Group Job Code 1172 training dataset <<< PAKAI INI NGGIH\n",
				"\n",
				"#group_1172 = payroll.groupby(['Job Code']).get_group(1172)\n",
				"\n",
				"#_sorted = group_1172.sort_values('Employee Identifier')\n",
				"#fiscal = pd.pivot_table(_sorted, values='Base Pay', index=['Fiscal Period'], columns='Employee Identifier')\n",
				"\n",
				"#fiscal = fiscal.diff()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# cleaned display table\n",
				"\n",
				"#fiscal.fillna(0, inplace=True)\n",
				"#fiscal = fiscal.drop(2016.00)\n",
				"\n",
				"#fiscal"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"\n",
				"\n",
				"# neg_cols = (payroll[numeric_cols] < 0).any()\n",
				"\n",
				"# if neg_cols.any():\n",
				"#     print(\"Terdapat nilai negatif pada kolom: \", end=\"\")\n",
				"#     print(\", \".join(neg_cols[neg_cols == True].index))\n",
				"# else:\n",
				"#     print(\"Tidak terdapat nilai negatif pada semua kolom numerik.\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# SUDAH AMAN 👍👍\n",
				"\n",
				"# null_cols = payroll.isnull().any()\n",
				"\n",
				"# if null_cols.any():\n",
				"#     print(\"Terdapat nilai NaN pada kolom: \", end=\"\")\n",
				"#     print(\", \".join(null_cols[null_cols == True].index))\n",
				"# else:\n",
				"#     print(\"Tidak terdapat nilai NaN pada semua kolom.\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# query job code indexing\n",
				"\n",
				"#for val in arr:\n",
				"    #new_df = payroll[payroll['Job Code'] == val]\n",
				"    #print(f\"DataFrame for job code {val}:\")\n",
				"    #display(new_df)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.8"
		},
		"orig_nbformat": 4
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
