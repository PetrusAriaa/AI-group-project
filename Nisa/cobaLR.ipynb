{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table\n",
    "\n",
    "dataPayment = '../Datasets/Employee_Payroll.csv'\n",
    "payroll = pd.read_csv(dataPayment)\n",
    "\n",
    "# set default value to 0 for NaN numerical data\n",
    "numeric_cols = payroll.select_dtypes(include=[np.number]).columns\n",
    "payroll[numeric_cols] = payroll[numeric_cols].clip(lower=0)\n",
    "\n",
    "\n",
    "payroll.fillna(0, inplace=True)\n",
    "payroll['Office'] = payroll['Office'].astype(int)\n",
    "\n",
    "# define column for 1/4 year discretization\n",
    "payroll['Fiscal Quarter'] = payroll['Fiscal Quarter']*0.25 - 0.25\n",
    "payroll['Fiscal Period'] = payroll['Fiscal Year'] + payroll['Fiscal Quarter']\n",
    "\n",
    "pd.to_datetime(payroll['Original Hire Date'])\n",
    "\n",
    "# parse hire date to get hire year\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].str.split('/').str[2]\n",
    "payroll['Original Hire Date'] = payroll['Original Hire Date'].astype(int)\n",
    "\n",
    "_work_year = payroll[\"Fiscal Period\"] - payroll['Original Hire Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify table column included\n",
    "\n",
    "payroll = payroll[['Fiscal Year', 'Fiscal Period', 'Job Code', 'Job Title', 'Base Pay', 'Position ID', 'Employee Identifier']]\n",
    "\n",
    "# add Working Year Column\n",
    "payroll[\"Working Year\"] = _work_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YANG INI JANGAN DIJALANKAN DULU YA GESSS :'\n",
    "\n",
    "arr = []\n",
    "\n",
    "try:\n",
    "    with open('./cache/ids.txt', \"r\") as f:\n",
    "        for _id in f:\n",
    "            arr.append(int(_id))\n",
    "except:\n",
    "    if not os.path.exists('./cache'):\n",
    "        os.mkdir('./cache')\n",
    "        \n",
    "    _index = payroll['Job Code'].unique()\n",
    "    for _id in _index:\n",
    "        counts = len(payroll.groupby(['Job Code']).get_group(_id))\n",
    "        if counts > 1000:\n",
    "            arr.append(str(_id))\n",
    "    with open('cache/ids.txt', 'w') as f:\n",
    "        for _id in arr:\n",
    "            f.write('%s\\n' % _id)\n",
    "    with open('cache/ids.txt', 'r') as f:\n",
    "        arr = []\n",
    "        for _id in f:\n",
    "            arr.append(int(_id)) \n",
    "finally:\n",
    "   f.close()\n",
    "\n",
    "# :return : <List> arr : list of unique job id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emps = []\n",
    "max = 0;\n",
    "for _id in arr:\n",
    "    df = payroll[payroll['Job Code'] == _id]\n",
    "    emp_id = df['Employee Identifier'].unique()\n",
    "    if len(emp_id) > 50:\n",
    "        l = 75\n",
    "    else:\n",
    "        l = len(emp_id)\n",
    "\n",
    "    for i in range(l):\n",
    "        for i in range(100):\n",
    "            _index = np.random.randint(0, l-1)\n",
    "            if emp_id[_index] not in emps:\n",
    "                emps.append(emp_id[_index])\n",
    "                break\n",
    "\n",
    "\n",
    "len(emps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = payroll[payroll['Employee Identifier'].isin(emps)]\n",
    "df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.variance = None\n",
    "        self.mean = None\n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.variance = np.std(data, axis=0)\n",
    "        self.mean = np.mean(data, axis=0)\n",
    "\n",
    "    def transform(self, data):\n",
    "        scaled = (data - self.mean)/self.variance\n",
    "        return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_id[['Job Code','Working Year']]\n",
    "Y = df_id['Base Pay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "x = scaler.transform(X)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,Y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,iterations,alpha):\n",
    "        self.iterations=iterations\n",
    "        self.alpha=alpha\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        return(1/(1+np.exp(-z)))\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        m=x.shape[0]\n",
    "        self.w = np.array([[5],[5]])\n",
    "        \n",
    "        cost_vals=[] \n",
    "        for i in range(self.iterations):\n",
    "            a= np.dot(x,self.w)\n",
    "            z=self.sigmoid(a)\n",
    "            \n",
    "            za = z.copy()\n",
    "            za[za <= 0] = 1\n",
    "            \n",
    "            zb = z.copy()\n",
    "            zb[1-zb <= 0] = 1\n",
    "            \n",
    "            ya = y.copy()\n",
    "            ya[1-ya <= 0] = 1\n",
    "            \n",
    "            cost = (-1/m) *( np.dot(y,np.log(z))+(np.dot((1-y),np.log(1-z))))\n",
    "            \n",
    "            cost_vals.append(cost)\n",
    "            \n",
    "            dw = np.dot(x.T,z-np.array([y])).mean()\n",
    "            \n",
    "            self.w=self.w-(self.alpha*dw)\n",
    "        print(self.w)\n",
    "    \n",
    "    def predict(self,x,threshold=0.5):\n",
    "        result = []\n",
    "        for i in range(x.shape[0]):\n",
    "            row = np.array(x.iloc[i])\n",
    "            probability=self.sigmoid(np.dot(row,self.w))\n",
    "            if(probability > threshold):\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(1000,0.1)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\n",
    "    'expected': model.predict(x_test),\n",
    "    'actual': np.array(y_test)\n",
    "})\n",
    "\n",
    "num_all = test.shape[0]\n",
    "num_true = test[test['expected'] == test['actual']].shape[0]\n",
    "\n",
    "accuracy = num_true/num_all\n",
    "print(\"accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
